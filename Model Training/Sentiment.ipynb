{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q transformers[torch]\n",
        "!pip install -q accelerate -U"
      ],
      "metadata": {
        "id": "x9HDg_jdcOEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130c2197-20fb-4168-e54e-3beb4f18face"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/280.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/280.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m276.5/280.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch"
      ],
      "metadata": {
        "id": "aX0VpLs9uBAM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "def adjust_to_num(dec):\n",
        "  if dec == 'positive':\n",
        "    return 2\n",
        "  elif dec == 'neutral':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/HackTJ 2024/Newskip')\n",
        "df = pd.read_csv('data.csv')\n",
        "df['label'] = df['decision'].apply(adjust_to_num)\n",
        "df = df.drop('decision', axis=1)\n",
        "df['text'] = df['title']\n",
        "df = df.drop('title', axis=1)\n",
        "df = df.drop(df[df['label'] == 1].index)\n",
        "train = df[:5745]\n",
        "test = df[5745:]\n",
        "#train.head()"
      ],
      "metadata": {
        "id": "vum7EIfOucQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text, sentiment = list(train['text']), list(train['label'])\n",
        "labels = train['label'].tolist()\n",
        "sentences = train['text'].tolist()"
      ],
      "metadata": {
        "id": "_2chPBy7vGDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "inputs = tokenizer(sentences, padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "mYw2ZynFwX7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "train_ds = NewsDataset(inputs, labels)"
      ],
      "metadata": {
        "id": "sOtG3ld_wsda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.__getitem__(0))"
      ],
      "metadata": {
        "id": "vKqIzWHuyB7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "id": "49Z6NfPZy_nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "9ZJg-tLRzv7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "APgwVU4W0I0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   torch.save(model.state_dict(), './model_better')"
      ],
      "metadata": {
        "id": "P0vWP0bY0vFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
        "model.load_state_dict(torch.load('./model_better'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "7THmuGgD9y01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred))*100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "VVs5yHPYKdk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for text in test['text']:\n",
        "  # Tokenize input text\n",
        "  inputs = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "  # Perform prediction\n",
        "  outputs = model(**inputs.to(device))\n",
        "  predicted_class = torch.argmax(outputs.logits)\n",
        "\n",
        "  # Interpret prediction\n",
        "  predictions.append(predicted_class)\n",
        "\n",
        "accuracy_fn(torch.tensor(predictions),torch.tensor(test['label'].tolist()))"
      ],
      "metadata": {
        "id": "HmoQgsymIGkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input text\n",
        "text = \"\"\n",
        "\n",
        "# Tokenize input text\n",
        "inputs = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "# Perform prediction\n",
        "outputs = model(**inputs.to(device))\n",
        "predicted_class = torch.argmax(outputs.logits)\n",
        "\n",
        "# Interpret prediction\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "predicted_sentiment = class_names[predicted_class]\n",
        "\n",
        "print(\"Predicted sentiment:\", predicted_sentiment)"
      ],
      "metadata": {
        "id": "Ccl6HioTIQIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/HackTJ 2024/Newskip')\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n",
        "def pred(input):\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
        "    model.load_state_dict(torch.load('./model_better', map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    text = input\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "    inputs = tokenizer(text, return_tensors='pt')\n",
        "    outputs = model(**inputs)\n",
        "    predicted_class = torch.argmax(outputs.logits)\n",
        "    class_names = ['negative', 'neutral', 'positive']\n",
        "    predicted_sentiment = class_names[predicted_class]\n",
        "    print(\"Predicted sentiment:\", predicted_sentiment)"
      ],
      "metadata": {
        "id": "I--MFvnNX25b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}